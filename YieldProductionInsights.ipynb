{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7M2ukSl2VYWg"
      },
      "source": [
        "## Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4a9a7ad8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import joblib\n",
        "from google.colab import files\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsY3tzS03YYx"
      },
      "source": [
        "# Load the dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19ed478b"
      },
      "outputs": [],
      "source": [
        "uploaded = files.upload()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3b73f1e4"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('yield_df.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JAumYqf3mJ5"
      },
      "source": [
        "# Initial Exploration of the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d91cb3c2"
      },
      "outputs": [],
      "source": [
        "# display the shape of the DataFrame\n",
        "print(\"Shape of the DataFrame:\", df.shape)\n",
        "\n",
        "# display first 5 rows of the dataframe to verify it has been loaded correctly\n",
        "display(df.head())\n",
        "\n",
        "# Display information about the DataFrame (like data types, non-null values, and etc.)\n",
        "print(\"\\nDataFrame Info:\")\n",
        "df.info()\n",
        "\n",
        "# Display descriptive statistics for numerical columns\n",
        "print(\"\\nDescriptive Statistics:\")\n",
        "display(df.describe())\n",
        "\n",
        "# Display descriptive statistics for categorical columns\n",
        "print(\"\\nDescriptive Statistics for Categorical Columns:\")\n",
        "display(df.describe(include='object'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAMLNkXQK26c"
      },
      "source": [
        "## Preprocess Dataset to get it ready for deeper exploratory analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTDVutV4J94k"
      },
      "outputs": [],
      "source": [
        "# Drop the 'Unnamed: 0' column as it is likely an index\n",
        "df = df.drop('Unnamed: 0', axis=1)\n",
        "\n",
        "# Display the first few rows to confirm the column is dropped\n",
        "display(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32636e4f"
      },
      "outputs": [],
      "source": [
        "# Check for missing values in each column\n",
        "print(\"Missing values per column:\")\n",
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0814b4ea"
      },
      "outputs": [],
      "source": [
        "# identify for duplicate rows\n",
        "duplicate_rows = df.duplicated().sum()\n",
        "print(f\"Number of duplicate rows: {duplicate_rows}\")\n",
        "\n",
        "# drop duplicate rows\n",
        "df = df.drop_duplicates()\n",
        "print(f\"Number of rows after removing duplicates: {df.shape[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3426feae"
      },
      "source": [
        "## Prepare and Save Original DataFrame for Streamlit and SQL\n",
        "\n",
        "To allow the Streamlit app to display original historical data, we need to save the DataFrame in its state *before* one-hot encoding. This ensures the app can access the non-encoded `Area` and `Item` names along with the numerical features and actual yield."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6838a099"
      },
      "outputs": [],
      "source": [
        "# Create a copy of the DataFrame before one-hot encoding to preserve original categorical values\n",
        "# This `df` state is after dropping 'Unnamed: 0' and duplicates, but before one-hot encoding.\n",
        "original_df_for_streamlit = df.copy()\n",
        "\n",
        "# Save this DataFrame\n",
        "joblib.dump(original_df_for_streamlit, 'original_df_for_streamlit.pkl')\n",
        "\n",
        "print(\"Original DataFrame (pre-one-hot encoding) saved as 'original_df_for_streamlit.pkl'!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef83023d"
      },
      "source": [
        "## Load Cleaned DataFrame into SQLite\n",
        "\n",
        "### Subtask:\n",
        "Establish an in-memory SQLite database connection and load the currently processed and cleaned `df` (crop yield data) into a SQL table.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "016ae401"
      },
      "outputs": [],
      "source": [
        "import sqlite3\n",
        "\n",
        "# Create an in-memory SQLite database connection\n",
        "conn = sqlite3.connect(':memory:')\n",
        "\n",
        "# Save the df DataFrame to a new SQL table named 'crop_yield_data'\n",
        "original_df_for_streamlit.to_sql('crop_yield_data', conn, if_exists='replace', index=False)\n",
        "\n",
        "print(\"DataFrame loaded into SQLite table 'crop_yield_data'.\")\n",
        "\n",
        "# Display the schema of the 'crop_yield_data' table\n",
        "print(\"\\nSchema of 'crop_yield_data' table:\")\n",
        "display(pd.read_sql_query(\"PRAGMA table_info(crop_yield_data);\", conn))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ceeff96"
      },
      "source": [
        "# Task\n",
        "Perform SQL data integrity checks on the `crop_yield_data` table by counting null values for each column and unique values for the 'Area', 'Item', and 'Year' columns. Display the results in separate pandas DataFrames."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "da17efa9"
      },
      "source": [
        "## Perform SQL Schema Inspection and Integrity Checks\n",
        "\n",
        "### Subtask:\n",
        "Perform SQL data integrity checks on the `crop_yield_data` table by counting null values for each column and unique values for the 'Area', 'Item', and 'Year' columns.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cee8ae1f"
      },
      "outputs": [],
      "source": [
        "null_counts_query = '''\n",
        "SELECT\n",
        "    SUM(CASE WHEN Area IS NULL THEN 1 ELSE 0 END) AS Area_Nulls,\n",
        "    SUM(CASE WHEN Item IS NULL THEN 1 ELSE 0 END) AS Item_Nulls,\n",
        "    SUM(CASE WHEN Year IS NULL THEN 1 ELSE 0 END) AS Year_Nulls,\n",
        "    SUM(CASE WHEN \"hg/ha_yield\" IS NULL THEN 1 ELSE 0 END) AS hg_ha_yield_Nulls,\n",
        "    SUM(CASE WHEN average_rain_fall_mm_per_year IS NULL THEN 1 ELSE 0 END) AS average_rain_fall_mm_per_year_Nulls,\n",
        "    SUM(CASE WHEN pesticides_tonnes IS NULL THEN 1 ELSE 0 END) AS pesticides_tonnes_Nulls,\n",
        "    SUM(CASE WHEN avg_temp IS NULL THEN 1 ELSE 0 END) AS avg_temp_Nulls\n",
        "FROM\n",
        "    crop_yield_data;\n",
        "'''\n",
        "\n",
        "null_counts_df = pd.read_sql_query(null_counts_query, conn)\n",
        "print(\"Null counts for each column:\")\n",
        "display(null_counts_df)\n",
        "\n",
        "unique_counts_query = '''\n",
        "SELECT\n",
        "    COUNT(DISTINCT Area) AS Unique_Areas,\n",
        "    COUNT(DISTINCT Item) AS Unique_Items,\n",
        "    COUNT(DISTINCT Year) AS Unique_Years\n",
        "FROM crop_yield_data;\n",
        "'''\n",
        "\n",
        "unique_counts_df = pd.read_sql_query(unique_counts_query, conn)\n",
        "print(\"\\nUnique counts for Area, Item, and Year:\")\n",
        "display(unique_counts_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57edc996"
      },
      "source": [
        "## Execute Advanced SQL Analytical Queries\n",
        "\n",
        "### Subtask:\n",
        "Craft and execute advanced SQL queries on the `crop_yield_data` table to derive new insights, such as finding top areas for specific crop yields, analyzing year-over-year changes, and calculating average yields under certain environmental conditions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9a7f5126"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 1. SQL query to find the top 5 areas with the highest average 'Maize' yield\n",
        "top_maize_areas_query = '''\n",
        "SELECT\n",
        "    Area,\n",
        "    AVG(\"hg/ha_yield\") AS Average_Yield\n",
        "FROM\n",
        "    crop_yield_data\n",
        "WHERE\n",
        "    Item = 'Maize'\n",
        "GROUP BY\n",
        "    Area\n",
        "ORDER BY\n",
        "    Average_Yield DESC\n",
        "LIMIT 5;\n",
        "'''\n",
        "top_maize_areas_df = pd.read_sql_query(top_maize_areas_query, conn)\n",
        "print(\"Top 5 areas with highest average Maize yield:\")\n",
        "display(top_maize_areas_df)\n",
        "\n",
        "# 2. SQL query to calculate the year-over-year yield change for 'Wheat' in 'India'\n",
        "india_wheat_yoy_query = '''\n",
        "WITH IndiaWheatYield AS (\n",
        "    SELECT\n",
        "        Year,\n",
        "        \"hg/ha_yield\" AS Current_Yield,\n",
        "        LAG(\"hg/ha_yield\", 1, 0) OVER (ORDER BY Year) AS Previous_Year_Yield\n",
        "    FROM\n",
        "        crop_yield_data\n",
        "    WHERE\n",
        "        Area = 'India' AND Item = 'Wheat'\n",
        ")\n",
        "SELECT\n",
        "    Year,\n",
        "    Current_Yield,\n",
        "    Previous_Year_Yield,\n",
        "    (Current_Yield - Previous_Year_Yield) AS YoY_Change\n",
        "FROM\n",
        "    IndiaWheatYield\n",
        "WHERE\n",
        "    Previous_Year_Yield != 0 -- Exclude the first year where Previous_Year_Yield is 0\n",
        "ORDER BY\n",
        "    Year;\n",
        "'''\n",
        "india_wheat_yoy_df = pd.read_sql_query(india_wheat_yoy_query, conn)\n",
        "print(\"\\nYear-over-year yield change for Wheat in India:\")\n",
        "display(india_wheat_yoy_df)\n",
        "\n",
        "# 3. SQL query to find the average yield for each crop ('Item') when avg_temp is above 25 degrees Celsius\n",
        "high_temp_yield_query = '''\n",
        "SELECT\n",
        "    Item,\n",
        "    AVG(\"hg/ha_yield\") AS Average_Yield_High_Temp\n",
        "FROM\n",
        "    crop_yield_data\n",
        "WHERE\n",
        "    avg_temp > 25\n",
        "GROUP BY\n",
        "    Item\n",
        "ORDER BY\n",
        "    Average_Yield_High_Temp DESC;\n",
        "'''\n",
        "high_temp_yield_df = pd.read_sql_query(high_temp_yield_query, conn)\n",
        "print(\"\\nAverage yield for each crop when average temperature is above 25°C:\")\n",
        "display(high_temp_yield_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8d23cbe"
      },
      "source": [
        "# Deeper exploration of the dataset\n",
        "Explore the dataset further by visualizing the distribution of numerical and categorical features, examining the relationships between features and the target variable, and analyzing correlations between numerical features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47fd4edb"
      },
      "source": [
        "## Visualize the distribution of numerical features\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bac01088"
      },
      "outputs": [],
      "source": [
        "numerical_cols = ['Year', 'hg/ha_yield', 'average_rain_fall_mm_per_year', 'pesticides_tonnes', 'avg_temp']\n",
        "\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "for i, col in enumerate(numerical_cols):\n",
        "    plt.subplot(2, 3, i + 1)\n",
        "    sns.histplot(data=df, x=col, kde=True)\n",
        "    plt.title(f'Distribution of {col}')\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel('Frequency')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5d976a61"
      },
      "source": [
        "## Explore the relationship between numerical features and the target variable\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8d98aff"
      },
      "outputs": [],
      "source": [
        "# create scatter plots for key environmental/management factors vs. yield\n",
        "plt.figure(figsize=(18, 5))\n",
        "\n",
        "# scatter plot: Average Rainfall vs. Yield\n",
        "plt.subplot(1, 3, 1)\n",
        "sns.scatterplot(x='average_rain_fall_mm_per_year', y='hg/ha_yield', data=df)\n",
        "plt.title(\"Average Rainfall vs. Yield\")\n",
        "plt.xlabel(\"Average Rainfall (mm/year)\")\n",
        "plt.ylabel(\"Yield (hg/ha)\")\n",
        "plt.grid(True)\n",
        "\n",
        "# scatter plot: Pesticides Tonnes vs. Yield\n",
        "plt.subplot(1, 3, 2)\n",
        "sns.scatterplot(x='pesticides_tonnes', y='hg/ha_yield', data=df)\n",
        "plt.title(\"Pesticides Tonnes vs. Yield\")\n",
        "plt.xlabel(\"Pesticides Tonnes\")\n",
        "plt.ylabel(\"Yield (hg/ha)\")\n",
        "plt.grid(True)\n",
        "\n",
        "# scatter plot: Average Temperature vs. Yield\n",
        "plt.subplot(1, 3, 3)\n",
        "sns.scatterplot(x='avg_temp', y='hg/ha_yield', data=df)\n",
        "plt.title(\"Average Temperature vs. Yield\")\n",
        "plt.xlabel(\"Average Temperature (°C)\")\n",
        "plt.ylabel(\"Yield (hg/ha)\")\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5c1b4721"
      },
      "source": [
        "## Investigate the relationship between categorical features and the target variable\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cf805c16"
      },
      "outputs": [],
      "source": [
        "# identify the top 10 most frequent areas based on the 'Area' column's value counts.\n",
        "top_10_areas = df['Area'].value_counts().nlargest(10).index.tolist()\n",
        "\n",
        "# Filtere DataFrame to include only the top 10 areas\n",
        "df_top_areas = df[df['Area'].isin(top_10_areas)]\n",
        "\n",
        "#  box plot to visualize the distribution of 'hg/ha_yield' for the top 10 area.\n",
        "plt.figure(figsize=(14, 7))\n",
        "sns.boxplot(x='Area', y='hg/ha_yield', data=df_top_areas, order=top_10_areas)\n",
        "plt.title('Distribution of Yield (hg/ha) Across Top 10 Areas')\n",
        "plt.xlabel('Area')\n",
        "plt.ylabel('Yield (hg/ha)')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "#  box plot to visualize the distribution of 'hg/ha_yield' for all unique 'Item' categories.\n",
        "plt.figure(figsize=(14, 7))\n",
        "sns.boxplot(x='Item', y='hg/ha_yield', data=df, order=df['Item'].value_counts().index)\n",
        "plt.title('Distribution of Yield (hg/ha) Across All Crop Items')\n",
        "plt.xlabel('Item')\n",
        "plt.ylabel('Yield (hg/ha)')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adbeb4f9"
      },
      "source": [
        "## Explore correlations between numerical features\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4c14e040"
      },
      "outputs": [],
      "source": [
        "# select numerical columns\n",
        "numerical_cols = ['Year', 'hg/ha_yield', 'average_rain_fall_mm_per_year', 'pesticides_tonnes', 'avg_temp']\n",
        "df_numerical = df[numerical_cols]\n",
        "\n",
        "# clculate the correlation matrix\n",
        "correlation_matrix = df_numerical.corr()\n",
        "\n",
        "# make the heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title('Correlation Matrix of Numerical Features')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCzLs-pK4FmQ"
      },
      "source": [
        "# Encoding categorical variables\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82077a64"
      },
      "outputs": [],
      "source": [
        "# Perform one-hot encoding for 'Area' and 'Item' columns\n",
        "df = pd.get_dummies(df, columns=['Area', 'Item'], drop_first=False)\n",
        "\n",
        "# Display the first few rows of the modified DataFrame to see the new columns\n",
        "display(df.head())\n",
        "\n",
        "# Display the shape of the DataFrame to see the increase in columns\n",
        "print(\"\\nShape of the DataFrame after one-hot encoding:\", df.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83a0a623"
      },
      "source": [
        "### Split data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8aee0616"
      },
      "outputs": [],
      "source": [
        "X = df.drop('hg/ha_yield', axis=1)\n",
        "y = df['hg/ha_yield']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67aca7d6"
      },
      "source": [
        "## Model selection and evaluation\n",
        "\n",
        "### Subtask:\n",
        "Train and evaluate multiple models to compare their performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JEpx1z3KnQq7"
      },
      "outputs": [],
      "source": [
        "X = df.drop('hg/ha_yield', axis=1)\n",
        "y = df['hg/ha_yield']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# make the columnsd aligned because crucial for consistent feature sets between train and test\n",
        "train_cols = X_train.columns\n",
        "test_cols = X_test.columns\n",
        "\n",
        "missing_in_test = set(train_cols) - set(test_cols)\n",
        "for c in missing_in_test:\n",
        "    X_test[c] = 0\n",
        "\n",
        "missing_in_train = set(test_cols) - set(train_cols)\n",
        "for c in missing_in_train:\n",
        "    X_train[c] = 0\n",
        "\n",
        "X_test = X_test[train_cols] #  the order of columns is the same\n",
        "\n",
        "# intiialize and train the models again\n",
        "models = {\n",
        "    \"Linear Regression\": LinearRegression(),\n",
        "    \"Ridge Regression\": Ridge(),\n",
        "    \"Lasso Regression\": Lasso(max_iter=10000), # Increased max_iter\n",
        "    \"Random Forest Regressor\": RandomForestRegressor(random_state=42),\n",
        "    \"Gradient Boosting Regressor\": GradientBoostingRegressor(random_state=42)\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"Training {name}...\")\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mse) # Calculate RMSE\n",
        "    mae = mean_absolute_error(y_test, y_pred) # Calculate MAE\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    results[name] = {\"MSE\": mse, \"RMSE\": rmse, \"MAE\": mae, \"R-squared\": r2} # storage of all metrics\n",
        "    print(f\"{name} - MSE: {mse:.2f}, RMSE: {rmse:.2f}, MAE: {mae:.2f}, R-squared: {r2:.2f}\\n\")\n",
        "\n",
        "print(\"\\nModel Evaluation Results:\")\n",
        "for name, metrics in results.items():\n",
        "    print(f\"{name}:\")\n",
        "    print(f\"  MSE: {metrics['MSE']:.2f}\")\n",
        "    print(f\"  RMSE: {metrics['RMSE']:.2f}\")\n",
        "    print(f\"  MAE: {metrics['MAE']:.2f}\")\n",
        "    print(f\"  R-squared: {metrics['R-squared']:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5b6d5e8"
      },
      "source": [
        "## Justify model choice\n",
        "\n",
        "### stask:\n",
        "Based on the evaluation, select the most appropriate model and justify the choice.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4f319e7"
      },
      "outputs": [],
      "source": [
        "# convedrt results dictionary to a pandas DataFrame for easier plotting\n",
        "results_df = pd.DataFrame.from_dict(results, orient='index')\n",
        "results_df = results_df.reset_index().rename(columns={'index': 'Model'})\n",
        "\n",
        "# make the DataFrame to have a single column for metrics (MSE, RMSE, MAE, and R-squared)\n",
        "melted_results_df = results_df.melt(id_vars='Model', var_name='Metric', value_name='Value')\n",
        "\n",
        "# create bar plots for MSE, RMSE, MAE and R-squared\n",
        "plt.figure(figsize=(18, 8))\n",
        "\n",
        "plt.subplot(2, 2, 1)\n",
        "sns.barplot(x='Model', y='Value', data=melted_results_df[melted_results_df['Metric'] == 'MSE'])\n",
        "plt.title('Model Performance Comparison (MSE)')\n",
        "plt.ylabel('Mean Squared Error (MSE)')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "sns.barplot(x='Model', y='Value', data=melted_results_df[melted_results_df['Metric'] == 'RMSE'])\n",
        "plt.title('Model Performance Comparison (RMSE)')\n",
        "plt.ylabel('Root Mean Squared Error (RMSE)')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.subplot(2, 2, 3)\n",
        "sns.barplot(x='Model', y='Value', data=melted_results_df[melted_results_df['Metric'] == 'MAE'])\n",
        "plt.title('Model Performance Comparison (MAE)')\n",
        "plt.ylabel('Mean Absolute Error (MAE)')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.subplot(2, 2, 4)\n",
        "sns.barplot(x='Model', y='Value', data=melted_results_df[melted_results_df['Metric'] == 'R-squared'])\n",
        "plt.title('Model Performance Comparison (R-squared)')\n",
        "plt.ylabel('R-squared')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcxiQM32iz47"
      },
      "source": [
        "## K-fold cross validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00f387a7"
      },
      "outputs": [],
      "source": [
        "# instantiate KFold\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "cv_results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"Performing cross-validation for {name}...\")\n",
        "\n",
        "    # cross-validation for MSE (negative)\n",
        "    mse_scores = cross_val_score(model, X, y, cv=kf, scoring='neg_mean_squared_error')\n",
        "    mean_mse = -mse_scores.mean() # Convert to positive MSE\n",
        "    std_mse = mse_scores.std()\n",
        "\n",
        "    # cross-validation for R-squared\n",
        "    r2_scores = cross_val_score(model, X, y, cv=kf, scoring='r2')\n",
        "    mean_r2 = r2_scores.mean()\n",
        "    std_r2 = r2_scores.std()\n",
        "\n",
        "    cv_results[name] = {\n",
        "        \"Mean MSE\": mean_mse,\n",
        "        \"Std MSE\": std_mse,\n",
        "        \"Mean R-squared\": mean_r2,\n",
        "        \"Std R-squared\": std_r2\n",
        "    }\n",
        "\n",
        "    print(f\"{name} - Mean MSE: {mean_mse:.2f} (± {std_mse:.2f}), Mean R-squared: {mean_r2:.2f} (± {std_r2:.2f})\\n\")\n",
        "\n",
        "print(\"\\nCross-Validation Results:\")\n",
        "for name, metrics in cv_results.items():\n",
        "    print(f\"{name}:\")\n",
        "    print(f\"  Mean MSE: {metrics['Mean MSE']:.2f} (± {metrics['Std MSE']:.2f})\")\n",
        "    print(f\"  Mean R-squared: {metrics['Mean R-squared']:.2f} (± {metrics['Std R-squared']:.2f})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63bc928e"
      },
      "source": [
        "## Hyperparameter Tuning for Random Forest Regressor using GridSearchCV\n",
        "\n",
        "\n",
        "Optimize the hyperparameters of the Random Forest Regressor using GridSearchCV."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a74c5c77"
      },
      "outputs": [],
      "source": [
        "# define the parameter grid for GridSearchCV\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200],  # Reduced number of trees\n",
        "    'max_depth': [10, 20],      # Reduced options for max depth\n",
        "    'min_samples_split': [2, 5],  # Reduced options for min samples split\n",
        "    'min_samples_leaf': [1, 2]     # Reduced options for min samples leaf\n",
        "}\n",
        "\n",
        "# initialize GridSearchCV\n",
        "# using the Random Forest Regressor\n",
        "grid_search = GridSearchCV(estimator=RandomForestRegressor(random_state=42),\n",
        "                           param_grid=param_grid,\n",
        "                           cv=3,       # reduced cross-validation folds for faster execution\n",
        "                           scoring='neg_mean_squared_error', # score using negative MSE\n",
        "                           n_jobs=-1)   # Use all available CPU cores\n",
        "\n",
        "print(\"Performing GridSearchCV for Random Forest Regressor...\")\n",
        "\n",
        "#  the grid search on the training data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"GridSearchCV complete.\")\n",
        "\n",
        "#  the best parameters found\n",
        "print(\"\\nBest parameters found: \", grid_search.best_params_)\n",
        "\n",
        "#  the best cross-validation score (negative MSE)\n",
        "print(\"\\nBest cross-validation score (negative MSE): \", grid_search.best_score_)\n",
        "\n",
        "#  the best estimator (the trained model with the best parameters)\n",
        "best_rf_model_tuned = grid_search.best_estimator_\n",
        "\n",
        "# evaluate the best tuned model on the test set\n",
        "y_pred_best_rf_tuned = best_rf_model_tuned.predict(X_test)\n",
        "mse_best_rf_tuned = mean_squared_error(y_test, y_pred_best_rf_tuned)\n",
        "rmse_best_rf_tuned = np.sqrt(mse_best_rf_tuned)\n",
        "mae_best_rf_tuned = mean_absolute_error(y_test, y_pred_best_rf_tuned)\n",
        "r2_best_rf_tuned = r2_score(y_test, y_pred_best_rf_tuned)\n",
        "\n",
        "print(\"\\nEvaluation of the best tuned Random Forest model on the test set:\")\n",
        "print(f\"  MSE: {mse_best_rf_tuned:.2f}\")\n",
        "print(f\"  RMSE: {rmse_best_rf_tuned:.2f}\")\n",
        "print(f\"  MAE: {mae_best_rf_tuned:.2f}\")\n",
        "print(f\"  R-squared: {r2_best_rf_tuned:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d79ab419"
      },
      "outputs": [],
      "source": [
        "\n",
        "best_model = best_rf_model_tuned\n",
        "\n",
        "\n",
        "area_cols = [col for col in X_train.columns if col.startswith('Area_')]\n",
        "item_cols = [col for col in X_train.columns if col.startswith('Item_')]\n",
        "\n",
        "\n",
        "area_results = {}\n",
        "item_results = {}\n",
        "\n",
        "\n",
        "print(\"Best tuned model selected for potential further analysis:\", type(best_model).__name__)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ax5xntyzi6Gw"
      },
      "source": [
        "## Best Model Performance Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58faac0e"
      },
      "source": [
        "## Visualization of Untuned vs. Tuned Random Forest Regressor Performance\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9858c9df"
      },
      "outputs": [],
      "source": [
        "#  the performance metrics for the untuned Random Forest Regressor\n",
        "\n",
        "untuned_rf_metrics = results[\"Random Forest Regressor\"]\n",
        "\n",
        "# the performance metrics for the tuned Random Forest Regressor\n",
        "\n",
        "tuned_rf_metrics = {\n",
        "    \"MSE\": mse_best_rf_tuned,\n",
        "    \"RMSE\": rmse_best_rf_tuned,\n",
        "    \"MAE\": mae_best_rf_tuned,\n",
        "    \"R-squared\": r2_best_rf_tuned\n",
        "}\n",
        "\n",
        "# Prepare data for plotting\n",
        "metrics_data = {\n",
        "    \"Metric\": [\"MSE\", \"RMSE\", \"MAE\", \"R-squared\"] * 2,\n",
        "    \"Value\": [\n",
        "        untuned_rf_metrics[\"MSE\"], untuned_rf_metrics[\"RMSE\"], untuned_rf_metrics[\"MAE\"], untuned_rf_metrics[\"R-squared\"],\n",
        "        tuned_rf_metrics[\"MSE\"], tuned_rf_metrics[\"RMSE\"], tuned_rf_metrics[\"MAE\"], tuned_rf_metrics[\"R-squared\"]\n",
        "    ],\n",
        "    \"Model\": [\"Untuned RF\"] * 4 + [\"Tuned RF\"] * 4\n",
        "}\n",
        "\n",
        "metrics_df = pd.DataFrame(metrics_data)\n",
        "\n",
        "# Create bar plots for each metric\n",
        "plt.figure(figsize=(14, 8))\n",
        "\n",
        "# Plot MSE\n",
        "plt.subplot(2, 2, 1)\n",
        "sns.barplot(x=\"Model\", y=\"Value\", data=metrics_df[metrics_df[\"Metric\"] == \"MSE\"])\n",
        "plt.title(\"MSE Comparison\")\n",
        "plt.ylabel(\"MSE\")\n",
        "\n",
        "# Plot RMSE\n",
        "plt.subplot(2, 2, 2)\n",
        "sns.barplot(x=\"Model\", y=\"Value\", data=metrics_df[metrics_df[\"Metric\"] == \"RMSE\"])\n",
        "plt.title(\"RMSE Comparison\")\n",
        "plt.ylabel(\"RMSE\")\n",
        "\n",
        "# Plot MAE\n",
        "plt.subplot(2, 2, 3)\n",
        "sns.barplot(x=\"Model\", y=\"Value\", data=metrics_df[metrics_df[\"Metric\"] == \"MAE\"])\n",
        "plt.title(\"MAE Comparison\")\n",
        "plt.ylabel(\"MAE\")\n",
        "\n",
        "# Plot R-squared\n",
        "plt.subplot(2, 2, 4)\n",
        "sns.barplot(x=\"Model\", y=\"Value\", data=metrics_df[metrics_df[\"Metric\"] == \"R-squared\"])\n",
        "plt.title(\"R-squared Comparison\")\n",
        "plt.ylabel(\"R-squared\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09yoB1b-jIkN"
      },
      "source": [
        "## Actual vs Predicted Crop Yield"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0f984528"
      },
      "outputs": [],
      "source": [
        "# get the best performing model (Random Forest Regressor)\n",
        "# use the untuned Random Forest model for comparison\n",
        "best_model = models[\"Random Forest Regressor\"]\n",
        "\n",
        "# make predictions on the test set\n",
        "y_pred_best_model = best_model.predict(X_test)\n",
        "\n",
        "# scatter plot of Actual vs. Predicted Yield\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x=y_test, y=y_pred_best_model)\n",
        "plt.xlabel(\"Actual Yield (hg/ha)\")\n",
        "plt.ylabel(\"Predicted Yield (hg/ha)\")\n",
        "plt.title(\"Actual vs. Predicted Crop Yield (Untuned Random Forest Regressor)\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4a4946cc"
      },
      "outputs": [],
      "source": [
        "# Load the original_df_for_streamlit for per-crop mean calculation\n",
        "# This DataFrame retains the original 'Item' column before one-hot encoding.\n",
        "original_df_for_streamlit = joblib.load('original_df_for_streamlit.pkl')\n",
        "print(\"original_df_for_streamlit loaded for per-crop mean calculation.\")\n",
        "\n",
        "# Calculate the mean yield for each crop ('Item') using the original_df_for_streamlit\n",
        "per_crop_mean_yield = original_df_for_streamlit.groupby('Item')['hg/ha_yield'].mean().to_dict()\n",
        "\n",
        "# Save the dictionary of per-crop mean yields\n",
        "joblib.dump(per_crop_mean_yield, 'per_crop_mean_yield.pkl')\n",
        "\n",
        "print(\"Per-crop mean yield calculated and saved as 'per_crop_mean_yield.pkl'!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef7fe2eb"
      },
      "source": [
        "## Mean Historical Yield per Crop Visualization\n",
        "\n",
        "This graph displays the average historical yield for each crop type present in the dataset, providing a quick comparison of productivity across different items."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33b69ca2"
      },
      "outputs": [],
      "source": [
        "# Load the per_crop_mean_yield dictionary\n",
        "# Ensure 'per_crop_mean_yield.pkl' has been created and saved previously\n",
        "per_crop_mean_yield = joblib.load('per_crop_mean_yield.pkl')\n",
        "\n",
        "\n",
        "# Convert the dictionary to a DataFrame for easier plotting\n",
        "yield_df = pd.DataFrame(list(per_crop_mean_yield.items()), columns=['Crop', 'Mean Yield (hg/ha)'])\n",
        "\n",
        "# Sort for better visualization\n",
        "yield_df = yield_df.sort_values(by='Mean Yield (hg/ha)', ascending=False)\n",
        "\n",
        "# Create the bar plot\n",
        "plt.figure(figsize=(12, 7))\n",
        "sns.barplot(x='Mean Yield (hg/ha)', y='Crop', data=yield_df, palette='viridis', hue='Crop', legend=False)\n",
        "plt.title('Mean Historical Yield per Crop')\n",
        "plt.xlabel('Mean Yield (hg/ha)')\n",
        "plt.ylabel('Crop Item')\n",
        "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdKhmss-jN9A"
      },
      "source": [
        "## Residual plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "088310aa"
      },
      "outputs": [],
      "source": [
        "# get the best performing model (Random Forest Regressor)\n",
        "# use the untuned Random Forest model for comparison\n",
        "best_model = models[\"Random Forest Regressor\"]\n",
        "\n",
        "# make predictions on the test set\n",
        "y_pred_best_model = best_model.predict(X_test)\n",
        "\n",
        "# calculate residuals\n",
        "residuals = y_test - y_pred_best_model\n",
        "\n",
        "# residual Plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x=y_pred_best_model, y=residuals)\n",
        "plt.axhline(y=0, color='r', linestyle='--')\n",
        "plt.xlabel(\"Predicted Yield (hg/ha)\")\n",
        "plt.ylabel(\"Residuals\")\n",
        "plt.title(\"Residual Plot (Untuned Random Forest Regressor)\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUPohIUYjRaA"
      },
      "source": [
        "## Feature Importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1330af95"
      },
      "outputs": [],
      "source": [
        "# Get the best performing model (Random Forest Regressor)\n",
        "# use the untuned Random Forest model for comparison\n",
        "best_model = models[\"Random Forest Regressor\"]\n",
        "\n",
        "# get feature importances\n",
        "# feature importances should be from the untuned model\n",
        "feature_importances = best_model.feature_importances_\n",
        "\n",
        "# create a DataFrame for better visualization\n",
        "features_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': feature_importances})\n",
        "\n",
        "# Sort by importance\n",
        "features_df = features_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Display the top 10 most important features\n",
        "display(features_df.head(10))\n",
        "\n",
        "# Plot feature importances (top 10)\n",
        "plt.figure(figsize=(12, 7))\n",
        "sns.barplot(x='Importance', y='Feature', data=features_df.head(10))\n",
        "plt.title(\"Top 10 Most Important Features (Untuned Random Forest Regressor)\")\n",
        "plt.xlabel(\"Importance\")\n",
        "plt.ylabel(\"Feature\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F95mKbht98yi"
      },
      "source": [
        "## Save best trained model to prep Streamlit deployment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "da170a5d"
      },
      "outputs": [],
      "source": [
        "# Save the best trained model\n",
        "joblib.dump(best_rf_model_tuned, 'best_rf_model_tuned.pkl')\n",
        "\n",
        "# Also save the list of columns from the training data\n",
        "# This is crucial for ensuring the Streamlit app receives inputs in the correct format\n",
        "joblib.dump(X_train.columns, 'training_columns.pkl')\n",
        "\n",
        "# Save feature importances for visualization in Streamlit app\n",
        "joblib.dump(features_df, 'feature_importances.pkl')\n",
        "\n",
        "# Save mean and standard deviation of y_train for contextual plots\n",
        "joblib.dump(y_train.mean(), 'y_train_mean.pkl')\n",
        "joblib.dump(y_train.std(), 'y_train_std.pkl')\n",
        "\n",
        "print(\"Tuned Random Forest model, training columns, feature importances, and y_train stats saved successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2da2090e"
      },
      "source": [
        "## requirements file for Streamlit App\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bba78a2"
      },
      "outputs": [],
      "source": [
        "%%writefile requirements.txt\n",
        "pandas\n",
        "scikit-learn\n",
        "streamlit\n",
        "matplotlib\n",
        "seaborn\n",
        "numpy\n",
        "altair==4.2.2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7101c24a"
      },
      "source": [
        "## Code for Streamlit App\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8cbe0f52"
      },
      "outputs": [],
      "source": [
        "%%writefile streamlit_app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import joblib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "st.set_page_config(layout='wide')\n",
        "\n",
        "st.title('Crop Yield Prediction App')\n",
        "st.write('Predict crop yield based on environmental factors and crop types.')\n",
        "\n",
        "# Load the trained model and training columns\n",
        "@st.cache_resource\n",
        "def load_data():\n",
        "    model = joblib.load('best_rf_model_tuned.pkl')\n",
        "    training_columns = joblib.load('training_columns.pkl')\n",
        "    feature_importances_df = joblib.load('feature_importances.pkl')\n",
        "    per_crop_mean_yield = joblib.load('per_crop_mean_yield.pkl')\n",
        "    original_df = joblib.load('original_df_for_streamlit.pkl') # Load original df\n",
        "    return model, training_columns, feature_importances_df, per_crop_mean_yield, original_df\n",
        "\n",
        "model, training_columns, feature_importances_df, per_crop_mean_yield, original_df = load_data()\n",
        "\n",
        "# Extract unique Area and Item names from training_columns for select boxes\n",
        "all_areas = sorted([col.replace('Area_', '') for col in training_columns if col.startswith('Area_')])\n",
        "all_items = sorted([col.replace('Item_', '') for col in training_columns if col.startswith('Item_')])\n",
        "\n",
        "# Sidebar for user input\n",
        "st.sidebar.header('Input Features')\n",
        "\n",
        "# User inputs\n",
        "selected_area = st.sidebar.selectbox('Area', all_areas)\n",
        "selected_item = st.sidebar.selectbox('Item', all_items)\n",
        "\n",
        "year = st.sidebar.slider('Year', min_value=1990, max_value=2013, value=2010) # Adjusted max_value to 2013\n",
        "rain_fall = st.sidebar.number_input('Average Rainfall (mm/year)', min_value=0.0, max_value=20000.0, value=1500.0)\n",
        "pesticides = st.sidebar.number_input('Pesticides (tonnes)', min_value=0.0, max_value=100000.0, value=5000.0)\n",
        "temperature = st.sidebar.number_input('Average Temperature (°C)', min_value=-20.0, max_value=40.0, value=20.0)\n",
        "\n",
        "\n",
        "if st.sidebar.button('Predict Yield'):\n",
        "    # Create a DataFrame for the current input, matching the structure of X_train\n",
        "    input_data = pd.DataFrame(0, index=[0], columns=training_columns)\n",
        "\n",
        "    # Populate numerical features\n",
        "    input_data['Year'] = year\n",
        "    input_data['average_rain_fall_mm_per_year'] = rain_fall\n",
        "    input_data['pesticides_tonnes'] = pesticides\n",
        "    input_data['avg_temp'] = temperature\n",
        "\n",
        "    # Populate one-hot encoded categorical features\n",
        "    if f'Area_{selected_area}' in input_data.columns:\n",
        "        input_data[f'Area_{selected_area}'] = 1\n",
        "    if f'Item_{selected_item}' in input_data.columns:\n",
        "        input_data[f'Item_{selected_item}'] = 1\n",
        "\n",
        "    # Ensure the order of columns is the same as during training\n",
        "    input_data = input_data[training_columns]\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = model.predict(input_data)[0]\n",
        "\n",
        "    st.subheader('Prediction Result')\n",
        "\n",
        "    # Display prediction prominently\n",
        "    col1, col2 = st.columns([1, 2])\n",
        "    with col1:\n",
        "        st.metric(\"Predicted Yield\", f\"{prediction:,.2f} hg/ha\")\n",
        "    with col2:\n",
        "        # Get historical mean for the selected crop\n",
        "        historical_yield_for_item = per_crop_mean_yield.get(selected_item, 0) # Use .get with default 0 if item not found\n",
        "\n",
        "        # --- New: Find and display historical data for comparison ---\n",
        "        historical_record = original_df[\n",
        "            (original_df['Area'] == selected_area) &\n",
        "            (original_df['Item'] == selected_item) &\n",
        "            (original_df['Year'] == year)\n",
        "        ]\n",
        "\n",
        "        plot_labels = ['Predicted', f'Avg Historical ({selected_item})']\n",
        "        plot_values = [prediction, historical_yield_for_item]\n",
        "\n",
        "        if not historical_record.empty:\n",
        "            actual_yield = historical_record['hg/ha_yield'].iloc[0]\n",
        "            historical_rain = historical_record['average_rain_fall_mm_per_year'].iloc[0]\n",
        "            historical_pesticides = historical_record['pesticides_tonnes'].iloc[0]\n",
        "            historical_temp = historical_record['avg_temp'].iloc[0]\n",
        "\n",
        "            st.markdown(f\"**Historical Data for {selected_item} in {selected_area} ({year}):**\")\n",
        "            st.write(f\"- **Actual Yield:** {actual_yield:,.2f} hg/ha\")\n",
        "            st.write(f\"- **Rainfall:** {historical_rain:,.2f} mm/year\")\n",
        "            st.write(f\"- **Pesticides:** {historical_pesticides:,.2f} tonnes\")\n",
        "            st.write(f\"- **Temperature:** {historical_temp:,.2f} °C\")\n",
        "            st.markdown(\"--- \")\n",
        "\n",
        "            plot_labels.insert(1, 'Actual')\n",
        "            plot_values.insert(1, actual_yield)\n",
        "\n",
        "        else:\n",
        "            st.info(f\"No exact historical record found for {selected_item} in {selected_area} for {year}. Displaying predicted vs. average historical.\")\n",
        "\n",
        "        # Contextual plot: Predicted vs. Actual vs. Average Historical Yield\n",
        "        fig_pred_vs_avg, ax_pred_vs_avg = plt.subplots(figsize=(6, 3))\n",
        "        bars = ax_pred_vs_avg.bar(plot_labels, plot_values, color=['skyblue', 'lightgreen', 'lightgray'][:len(plot_labels)])\n",
        "        ax_pred_vs_avg.set_ylabel('Yield (hg/ha)')\n",
        "        ax_pred_vs_avg.set_title(f'Yield Comparison for {selected_item}')\n",
        "        for bar in bars:\n",
        "            yval = bar.get_height()\n",
        "            ax_pred_vs_avg.text(bar.get_x() + bar.get_width()/2, yval + 500, round(yval, 0), ha='center', va='bottom', fontsize=8)\n",
        "        st.pyplot(fig_pred_vs_avg)\n",
        "\n",
        "    st.markdown(\"--- \")\n",
        "\n",
        "# General Model Insights (Feature Importance)\n",
        "st.subheader('Model Insights: Feature Importance')\n",
        "with st.expander(\"View Feature Importance\", expanded=False):\n",
        "    fig_feature_imp, ax_feature_imp = plt.subplots(figsize=(10, 6))\n",
        "    sns.barplot(x='Importance', y='Feature', data=feature_importances_df.head(10), ax=ax_feature_imp)\n",
        "    ax_feature_imp.set_title(\"Top 10 Most Important Features\")\n",
        "    ax_feature_imp.set_xlabel(\"Importance\")\n",
        "    ax_feature_imp.set_ylabel(\"Feature\")\n",
        "    st.pyplot(fig_feature_imp)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}